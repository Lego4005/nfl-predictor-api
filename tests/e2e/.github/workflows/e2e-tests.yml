name: E2E Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
        test-type: [smoke, integration, performance]
      fail-fast: false

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: nfl_predictor_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_HOST_AUTH_METHOD: trust
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        ports:
          - 6380:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            postgresql-client \
            redis-tools \
            curl \
            wget

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-production.txt
          pip install -r tests/e2e/requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install --with-deps ${{ matrix.browser }}

      - name: Verify services are running
        run: |
          # Check PostgreSQL
          pg_isready -h localhost -p 5433 -U test_user

          # Check Redis
          redis-cli -h localhost -p 6380 ping

      - name: Setup test database
        run: |
          export DATABASE_URL="postgresql://test_user:test_pass@localhost:5433/nfl_predictor_test"
          python -c "from database import run_migrations; run_migrations()"

      - name: Start test server
        run: |
          export DATABASE_URL="postgresql://test_user:test_pass@localhost:5433/nfl_predictor_test"
          export REDIS_URL="redis://localhost:6380/1"
          export API_HOST="localhost"
          export API_PORT="8001"
          export DEBUG="true"
          export TESTING="true"

          python -m uvicorn src.api.app:app --host localhost --port 8001 &

          # Wait for server to be ready
          timeout 30 bash -c 'until curl -f http://localhost:8001/health; do sleep 1; done'

      - name: Run E2E tests
        run: |
          export TEST_ENV="ci"
          export TEST_BASE_URL="http://localhost:8001"
          export TEST_DATABASE_URL="postgresql://test_user:test_pass@localhost:5433/nfl_predictor_test"
          export TEST_REDIS_URL="redis://localhost:6380/1"
          export TEST_BROWSER="${{ matrix.browser }}"
          export TEST_HEADLESS="true"
          export PYTHONPATH="${PWD}"

          # Run specific test type
          case "${{ matrix.test-type }}" in
            smoke)
              python tests/e2e/scripts/run_tests.py -m smoke --html-report --junit-xml --workers 2
              ;;
            integration)
              python tests/e2e/scripts/run_tests.py -m integration --html-report --junit-xml --workers 2
              ;;
            performance)
              python tests/e2e/scripts/run_tests.py --performance --html-report --junit-xml --workers 1
              ;;
          esac

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.browser }}-${{ matrix.test-type }}
          path: |
            test-results/
            !test-results/videos/
          retention-days: 7

      - name: Upload test videos
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-videos-${{ matrix.browser }}-${{ matrix.test-type }}
          path: test-results/videos/
          retention-days: 3

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-screenshots-${{ matrix.browser }}-${{ matrix.test-type }}
          path: test-results/screenshots/
          retention-days: 3

      - name: Publish test results
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: E2E Tests (${{ matrix.browser }}-${{ matrix.test-type }})
          path: test-results/reports/junit.xml
          reporter: java-junit

      - name: Comment PR with test results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = 'test-results/reports/test_summary.json';

            if (fs.existsSync(path)) {
              const summary = JSON.parse(fs.readFileSync(path, 'utf8'));
              const duration = Math.round(summary.duration_seconds);
              const browser = '${{ matrix.browser }}';
              const testType = '${{ matrix.test-type }}';

              const body = `## E2E Test Results (${browser} - ${testType})

              - **Duration:** ${duration}s
              - **Environment:** ${summary.environment}
              - **Browser:** ${browser}
              - **Test Type:** ${testType}

              [View detailed results in the Actions tab](${context.payload.repository.html_url}/actions/runs/${context.runId})
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }

  load-testing:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[load-test]')
    timeout-minutes: 45

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: nfl_predictor_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        ports:
          - 6380:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements-production.txt
          pip install -r tests/e2e/requirements.txt
          pip install locust

      - name: Setup test database
        run: |
          export DATABASE_URL="postgresql://test_user:test_pass@localhost:5433/nfl_predictor_test"
          python -c "from database import run_migrations; run_migrations()"

      - name: Start test server
        run: |
          export DATABASE_URL="postgresql://test_user:test_pass@localhost:5433/nfl_predictor_test"
          export REDIS_URL="redis://localhost:6380/1"
          python -m uvicorn src.api.app:app --host localhost --port 8001 &
          sleep 10

      - name: Run load tests
        run: |
          export TEST_CONCURRENT_USERS=100
          python tests/e2e/scripts/run_tests.py --performance --workers 1

          # Also run Locust load tests if available
          if [ -f "tests/e2e/locustfile.py" ]; then
            locust -f tests/e2e/locustfile.py --host=http://localhost:8001 \
              --users 50 --spawn-rate 5 --run-time 5m --html test-results/reports/locust-report.html
          fi

      - name: Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: test-results/reports/
          retention-days: 14

  test-summary:
    runs-on: ubuntu-latest
    needs: [e2e-tests]
    if: always()

    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: all-test-results

      - name: Generate test summary
        run: |
          echo "# E2E Test Summary" > test_summary.md
          echo "" >> test_summary.md

          for dir in all-test-results/test-results-*; do
            if [ -d "$dir" ]; then
              browser_type=$(basename "$dir" | cut -d'-' -f3-4)
              echo "## $browser_type" >> test_summary.md

              if [ -f "$dir/test-results/reports/test_summary.json" ]; then
                python3 -c "
          import json
          with open('$dir/test-results/reports/test_summary.json') as f:
              data = json.load(f)
              duration = round(data.get('duration_seconds', 0))
              print(f'- Duration: {duration}s')
              print(f'- Environment: {data.get(\"environment\", \"unknown\")}')
              " >> test_summary.md
              fi
              echo "" >> test_summary.md
            fi
          done

      - name: Upload summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test_summary.md

  docker-e2e:
    runs-on: ubuntu-latest
    if: contains(github.event.head_commit.message, '[docker-test]')
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build and run E2E tests in Docker
        run: |
          # Build test images
          docker-compose -f tests/e2e/docker-compose.test.yml build

          # Run E2E tests
          docker-compose -f tests/e2e/docker-compose.test.yml --profile test up --abort-on-container-exit

      - name: Copy test results from container
        if: always()
        run: |
          # Copy results from Docker volume
          docker-compose -f tests/e2e/docker-compose.test.yml cp e2e-tests:/app/test-results ./test-results

      - name: Upload Docker test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: docker-test-results
          path: test-results/

      - name: Cleanup Docker
        if: always()
        run: |
          docker-compose -f tests/e2e/docker-compose.test.yml down -v